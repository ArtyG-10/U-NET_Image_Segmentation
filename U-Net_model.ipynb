{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe7213b-8757-4961-9622-d8302d26cac6",
   "metadata": {
    "id": "0fe7213b-8757-4961-9622-d8302d26cac6",
    "outputId": "b4b32627-1d47-4e12-e08b-3629e408589b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (from pycocotools) (2.2.6)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (from scikit-image) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (from scikit-image) (1.16.3)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (from scikit-image) (3.6.1)\n",
      "Requirement already satisfied: pillow>=10.1 in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (from scikit-image) (12.0.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (from scikit-image) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (from scikit-image) (2025.10.16)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (from scikit-image) (25.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\arturo\\desktop\\cs553\\.venv\\lib\\site-packages (from scikit-image) (0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c76f260-6bd1-427f-9a8e-fc5b3cfea3b7",
   "metadata": {
    "id": "3c76f260-6bd1-427f-9a8e-fc5b3cfea3b7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn, numpy as np, torchvision.transforms.v2 as T\n",
    "import torch, dotenv, os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from matplotlib import pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "data_path = Path(os.getenv(\"DATAPATH\"))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2add5f75",
   "metadata": {
    "id": "2add5f75"
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "categories = ['person', 'car', 'horse'] # Example categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f8c7f0-ea6e-473d-9f26-caa121056f36",
   "metadata": {
    "id": "e3f8c7f0-ea6e-473d-9f26-caa121056f36"
   },
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, annotation_file, categories=['horse']):\n",
    "        super().__init__()\n",
    "        self.coco = COCO(data_path/\"annotations\"/annotation_file)\n",
    "\n",
    "        self.category_ids = self.coco.getCatIds(categories)\n",
    "        self.image_ids = self.coco.getImgIds(catIds=self.category_ids)\n",
    "\n",
    "        self.T = T.Compose([\n",
    "            T.ToImage(),\n",
    "            T.ToDtype(torch.float32, scale=True)\n",
    "        ])\n",
    "        self.P = T.Pad(padding=30, padding_mode='symmetric')\n",
    "        self.P2 = T.Pad(padding=30)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, list[torch.Tensor]]:\n",
    "        img_id = [self.image_ids[index]]\n",
    "        annotation_ids = self.coco.getAnnIds(imgIds=img_id, catIds=self.category_ids, iscrowd=None)\n",
    "\n",
    "        return (\n",
    "            self.P(self.T(io.imread(data_path/\"val2017\"/self.coco.loadImgs(img_id)[0]['file_name']))),\n",
    "            torch.stack([self.P2(self.T(self.coco.annToMask(ann))) for ann in self.coco.loadAnns(annotation_ids)], dim=0)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fda0c2a-a166-45ec-bb59-745968891388",
   "metadata": {
    "id": "5fda0c2a-a166-45ec-bb59-745968891388",
    "outputId": "5fbf9df0-6e6a-431e-fec7-27bf829bbf24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.65s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "ds_val = DS('instances_val2017.json')\n",
    "dl_val = DataLoader(ds_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6173759-c977-4863-b829-05d2569cb6a7",
   "metadata": {
    "id": "c6173759-c977-4863-b829-05d2569cb6a7",
    "outputId": "099f0df6-c63b-4c6e-ce68-0ea94baf0baa"
   },
   "outputs": [],
   "source": [
    "def crop(tensor: torch.Tensor, target):\n",
    "    offset_x = (tensor.shape[-2] - target[-2]) // 2\n",
    "    offset_y = (tensor.shape[-1] - target[-1]) // 2\n",
    "    return tensor[:, :, offset_x:(offset_x+target[-2]), offset_y:(offset_y+target[-1])]\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, categories):\n",
    "        super().__init__()\n",
    "        s = nn.Sequential\n",
    "\n",
    "        self.contracting_layers = nn.ModuleList([\n",
    "            s(\n",
    "                nn.Conv2d(3, 64, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 64, 3),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(64, 128, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(128, 128, 3),\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(128, 256, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, 3),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(256, 512, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(512, 512, 3),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.center = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(512, 1024, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, 1024, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(1024, 512, 2, 2)\n",
    "        )\n",
    "\n",
    "        self.expanding_layers = nn.ModuleList([\n",
    "            s(\n",
    "                nn.Conv2d(1024, 512, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(512, 512, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "            ),\n",
    "            s(\n",
    "                nn.Conv2d(512, 256, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "            ),\n",
    "            s(\n",
    "                nn.Conv2d(256, 128, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(128, 128, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "            ),\n",
    "            s(\n",
    "                nn.Conv2d(128, 64, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 64, 3),\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        self.final = nn.Conv2d(64, categories + 1, 1) # +1 for background\n",
    "\n",
    "    def forward(self, x):\n",
    "        c_layer_outputs = []\n",
    "\n",
    "        for layer in self.contracting_layers:\n",
    "            x = layer(x)\n",
    "            c_layer_outputs.append(x)\n",
    "\n",
    "        x = self.center(c_layer_outputs[-1])\n",
    "\n",
    "        for i, layer in enumerate(self.expanding_layers, 1):\n",
    "            x = layer(torch.concat(\n",
    "                [crop(c_layer_outputs[-i], x.shape), x],\n",
    "                dim=1\n",
    "            ))\n",
    "        \n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1cd151d",
   "metadata": {
    "id": "e1cd151d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 356, 516])\n",
      "torch.Size([1, 3, 540, 700])\n",
      "torch.Size([1, 1, 540, 700])\n",
      "torch.Size([1, 1, 356, 516])\n"
     ]
    }
   ],
   "source": [
    "model = UNet(len(categories)).to(device)\n",
    "\n",
    "img, masks = next(iter(dl_val))\n",
    "img = img.to(device); masks = list(map(lambda m: m.to(device), masks))\n",
    "y = model(img)\n",
    "print(y.shape)\n",
    "print(img.shape)\n",
    "print(masks[0].shape)\n",
    "print(crop(masks[0], y.shape).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "doVJHlrraYGW",
   "metadata": {
    "id": "doVJHlrraYGW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 60, 80])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Base_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        s = nn.Sequential\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            s(\n",
    "                nn.Conv2d(3, 64, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 64, 3),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(64, 128, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(128, 128, 3),\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(128, 256, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, 3),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(256, 512, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(512, 512, 3),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # output layer\n",
    "        self.output = nn.Conv2d(512, 2, kernel_size=1)\n",
    "        self.activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.output(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "base_model = Base_CNN().to(device)\n",
    "base_model(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25cb46-c1d7-483b-b3df-0cc0af6ff1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
