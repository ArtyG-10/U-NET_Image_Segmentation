{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe7213b-8757-4961-9622-d8302d26cac6",
   "metadata": {
    "id": "0fe7213b-8757-4961-9622-d8302d26cac6",
    "outputId": "b4b32627-1d47-4e12-e08b-3629e408589b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /home/brambles/anaconda3/lib/python3.13/site-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in /home/brambles/anaconda3/lib/python3.13/site-packages (from pycocotools) (2.1.3)\n",
      "Requirement already satisfied: scikit-image in /home/brambles/anaconda3/lib/python3.13/site-packages (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.24 in /home/brambles/anaconda3/lib/python3.13/site-packages (from scikit-image) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.11.4 in /home/brambles/anaconda3/lib/python3.13/site-packages (from scikit-image) (1.16.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/brambles/anaconda3/lib/python3.13/site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: pillow>=10.1 in /home/brambles/anaconda3/lib/python3.13/site-packages (from scikit-image) (11.1.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /home/brambles/anaconda3/lib/python3.13/site-packages (from scikit-image) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/brambles/anaconda3/lib/python3.13/site-packages (from scikit-image) (2025.10.16)\n",
      "Requirement already satisfied: packaging>=21 in /home/brambles/anaconda3/lib/python3.13/site-packages (from scikit-image) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /home/brambles/anaconda3/lib/python3.13/site-packages (from scikit-image) (0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c76f260-6bd1-427f-9a8e-fc5b3cfea3b7",
   "metadata": {
    "id": "3c76f260-6bd1-427f-9a8e-fc5b3cfea3b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 3\n",
      "python-dotenv could not parse statement starting at line 5\n",
      "python-dotenv could not parse statement starting at line 6\n",
      "python-dotenv could not parse statement starting at line 8\n",
      "python-dotenv could not parse statement starting at line 9\n",
      "python-dotenv could not parse statement starting at line 10\n",
      "python-dotenv could not parse statement starting at line 11\n",
      "python-dotenv could not parse statement starting at line 18\n",
      "python-dotenv could not parse statement starting at line 21\n",
      "python-dotenv could not parse statement starting at line 28\n",
      "python-dotenv could not parse statement starting at line 30\n",
      "python-dotenv could not parse statement starting at line 32\n",
      "python-dotenv could not parse statement starting at line 33\n",
      "python-dotenv could not parse statement starting at line 37\n",
      "python-dotenv could not parse statement starting at line 40\n",
      "python-dotenv could not parse statement starting at line 42\n",
      "python-dotenv could not parse statement starting at line 45\n",
      "python-dotenv could not parse statement starting at line 46\n",
      "python-dotenv could not parse statement starting at line 47\n",
      "python-dotenv could not parse statement starting at line 53\n",
      "python-dotenv could not parse statement starting at line 56\n",
      "python-dotenv could not parse statement starting at line 57\n",
      "python-dotenv could not parse statement starting at line 60\n",
      "python-dotenv could not parse statement starting at line 66\n",
      "python-dotenv could not parse statement starting at line 68\n",
      "python-dotenv could not parse statement starting at line 73\n",
      "python-dotenv could not parse statement starting at line 75\n",
      "python-dotenv could not parse statement starting at line 80\n",
      "python-dotenv could not parse statement starting at line 82\n",
      "python-dotenv could not parse statement starting at line 87\n",
      "python-dotenv could not parse statement starting at line 89\n",
      "python-dotenv could not parse statement starting at line 96\n",
      "python-dotenv could not parse statement starting at line 97\n",
      "python-dotenv could not parse statement starting at line 98\n",
      "python-dotenv could not parse statement starting at line 103\n",
      "python-dotenv could not parse statement starting at line 105\n",
      "python-dotenv could not parse statement starting at line 107\n",
      "python-dotenv could not parse statement starting at line 110\n",
      "python-dotenv could not parse statement starting at line 112\n",
      "python-dotenv could not parse statement starting at line 114\n",
      "python-dotenv could not parse statement starting at line 117\n",
      "python-dotenv could not parse statement starting at line 119\n",
      "python-dotenv could not parse statement starting at line 121\n",
      "python-dotenv could not parse statement starting at line 124\n",
      "python-dotenv could not parse statement starting at line 126\n",
      "python-dotenv could not parse statement starting at line 132\n",
      "python-dotenv could not parse statement starting at line 135\n",
      "python-dotenv could not parse statement starting at line 141\n",
      "python-dotenv could not parse statement starting at line 144\n",
      "python-dotenv could not parse statement starting at line 147\n",
      "python-dotenv could not parse statement starting at line 152\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn, numpy as np, torchvision.transforms.v2 as T\n",
    "import torch, dotenv, os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from matplotlib import pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "data_path = Path(os.getenv(\"DATAPATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2add5f75",
   "metadata": {
    "id": "2add5f75"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f8c7f0-ea6e-473d-9f26-caa121056f36",
   "metadata": {
    "id": "e3f8c7f0-ea6e-473d-9f26-caa121056f36"
   },
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, annotation_file, categories=['horse']):\n",
    "        super().__init__()\n",
    "        self.coco = COCO(data_path/\"annotations\"/annotation_file)\n",
    "        self.category_ids = self.coco.getCatIds(categories)\n",
    "        self.image_ids = self.coco.getImgIds(catIds=self.category_ids)\n",
    "        self.T = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Resize((572, 572))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, list[torch.Tensor]]:\n",
    "        img_id = [self.image_ids[index]]\n",
    "        annotation_ids = self.coco.getAnnIds(imgIds=img_id, catIds=self.category_ids, iscrowd=None)\n",
    "\n",
    "        return (\n",
    "            self.T(io.imread(data_path/\"val2017\"/self.coco.loadImgs(img_id)[0]['file_name'])),\n",
    "            torch.stack([self.T(self.coco.annToMask(ann)) for ann in self.coco.loadAnns(annotation_ids)], dim=0)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2cc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    return (\n",
    "        torch.stack([item[0] for item in batch], dim=0),\n",
    "        [item[1] for item in batch]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fda0c2a-a166-45ec-bb59-745968891388",
   "metadata": {
    "id": "5fda0c2a-a166-45ec-bb59-745968891388",
    "outputId": "5fbf9df0-6e6a-431e-fec7-27bf829bbf24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brambles/anaconda3/lib/python3.13/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds_val = DS('instances_val2017.json')\n",
    "dl_val = DataLoader(ds_val, batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6173759-c977-4863-b829-05d2569cb6a7",
   "metadata": {
    "id": "c6173759-c977-4863-b829-05d2569cb6a7",
    "outputId": "099f0df6-c63b-4c6e-ce68-0ea94baf0baa"
   },
   "outputs": [],
   "source": [
    "\n",
    "def crop(tensor: torch.Tensor, size: int):\n",
    "    offset = (tensor.shape[-1] - size) // 2\n",
    "    return tensor[:, :, offset:(offset+size), offset:(offset+size)]\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        s = nn.Sequential\n",
    "\n",
    "        self.contracting_layers = [\n",
    "            s(\n",
    "                nn.Conv2d(3, 64, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 64, 3),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(64, 128, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(128, 128, 3),\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(128, 256, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, 3),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(256, 512, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(512, 512, 3),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        self.center = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(512, 1024, 3),\n",
    "            nn.Conv2d(1024, 1024, 3),\n",
    "            nn.ConvTranspose2d(1024, 512, 2, 2)\n",
    "        )\n",
    "\n",
    "        self.expanding_layers = [\n",
    "            s(\n",
    "                nn.Conv2d(1024, 512, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(512, 512, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "            ),\n",
    "            s(\n",
    "                nn.Conv2d(512, 256, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "            ),\n",
    "            s(\n",
    "                nn.Conv2d(256, 128, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(128, 128, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "            ),\n",
    "            s(\n",
    "                nn.Conv2d(128, 64, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 64, 3),\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        self.final = nn.Conv2d(64, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        c_layer_outputs = []\n",
    "\n",
    "        for layer in self.contracting_layers:\n",
    "            x = layer(x)\n",
    "            c_layer_outputs.append(x)\n",
    "\n",
    "        x = self.center(c_layer_outputs[-1])\n",
    "\n",
    "        for i, layer in enumerate(self.expanding_layers, 1):\n",
    "            x = layer(torch.concat(\n",
    "                [crop(c_layer_outputs[-i], x.shape[-1]), x],\n",
    "                dim=1\n",
    "            ))\n",
    "        \n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1cd151d",
   "metadata": {
    "id": "e1cd151d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 388, 388])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet()\n",
    "\n",
    "imgs, masks = next(iter(dl_val))\n",
    "model(imgs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "doVJHlrraYGW",
   "metadata": {
    "id": "doVJHlrraYGW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 64, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Base_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        s = nn.Sequential\n",
    "\n",
    "        self.layers = [\n",
    "            s(\n",
    "                nn.Conv2d(3, 64, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 64, 3),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(64, 128, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(128, 128, 3),\n",
    "                nn.ReLU(),\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(128, 256, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(256, 256, 3),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            s(\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(256, 512, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(512, 512, 3),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # output layer\n",
    "        self.output = nn.Conv2d(512, 2, kernel_size=1)\n",
    "        self.activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.output(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "base_model = Base_CNN()\n",
    "base_model(imgs).shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
